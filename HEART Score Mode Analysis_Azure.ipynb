{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddafa92f",
   "metadata": {},
   "source": [
    "# HEART Score Subscore-based Mode Analysis\n",
    "\n",
    "Compared to the one-pass HEART score method, in which GPT-3.5-turbo is queried to retrieve all subscores at once and return each subscore and total score, this method aims to evaluate each subscore a multitude of times. GPT will be queried 10 times for each subscore, and the most common output or mode of the subscore will be the subscore used for the final HEART score generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e21603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99923cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /etc/environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "\n",
    "import os\n",
    "\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "openai.api_base = \"***REMOVED***\"\n",
    "\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = \"***REMOVED***\"\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "response = openai.Completion.create(\n",
    "\n",
    "  engine=\"decile-heart-score-gpt35\",\n",
    "\n",
    "  prompt=\"The cow jumped over the \",\n",
    "\n",
    "  temperature=1,\n",
    "\n",
    "  max_tokens=100,\n",
    "\n",
    "  top_p=0.5,\n",
    "\n",
    "  frequency_penalty=0,\n",
    "\n",
    "  presence_penalty=0,\n",
    "\n",
    "  stop=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeefc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cedab7",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-05-15\" \n",
    "openai.api_key = \"***REMOVED***\" #os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "openai.api_base = \"***REMOVED***\" #os.getenv(\"AZURE_OPENAI_ENDPOINT\") # your endpoint should look like the following https://YOUR_RESOURCE_NAME.openai.azure.com/\n",
    "deployment_name = \"decile-heart-score-gpt35-16k\"\n",
    "\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=deployment_name, # The deployment name you chose when you deployed the GPT-35-Turbo or GPT-4 model.\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# print(response)\n",
    "\n",
    "# print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49834f75",
   "metadata": {},
   "source": [
    "### Reading in all encounter notes from one pre-compiled txt document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db83fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in read mode\n",
    "with open('Test1doc.txt', 'r') as file:\n",
    "    # Read the contents of the file into a variable\n",
    "    file_contents = file.read()\n",
    "\n",
    "# Print the contents of the file\n",
    "print(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolateString(ch1,ch2,s):\n",
    "    return s[s.find(ch1)+1:s.find(ch2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8860ccd9",
   "metadata": {},
   "source": [
    "### Mode Analysis for History Subscore\n",
    "#### Repeated GPT Analysis of Note #1 for history subscore 10 times. Then, display mode of history subscore to ideally improve accuracy and precision of subscore.\n",
    "\n",
    "Based on all of the patient's notes below, and considering the patient's symptoms and past medical conditions, please choose between the following options to rate their history as: [Slightly suspicious (0)] [Moderately suspicious (1)] [Highly suspicious (2)] [Not enough information to determine History score (9)] Please provide your answer in brackets by choosing between the answers above (e.g. [Slightly suspicious (0)] ). No Prose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78274ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyList = []\n",
    "prompt = \"Based on all of the patient's notes below, and considering the patient's symptoms and past medical conditions, please choose between the following options to rate their history as: [Slightly suspicious (0)] [Moderately suspicious (1)] [Highly suspicious (2)] [Not enough information to determine History score (9)] Please provide your answer in brackets by choosing between the answers above (e.g. [Slightly suspicious (0)] ). No Prose.\"\n",
    "for x in range(0, 9):\n",
    "    messages = [{\"role\": \"user\", \"content\": (prompt + file_contents)}]\n",
    "    response = openai.ChatCompletion.create(engine=deployment_name, messages=messages)\n",
    "    for i, choice in enumerate(response[\"choices\"], start=1):\n",
    "        phrase = choice[\"message\"][\"content\"]\n",
    "        for ch in phrase:\n",
    "            if ch.isnumeric():\n",
    "                historyList.append(ch)\n",
    "        print(choice[\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99424c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeHistory = max(set(historyList), key=historyList.count)\n",
    "print(modeHistory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324832b",
   "metadata": {},
   "source": [
    "### Mode Analysis for EKG Subscore\n",
    "#### Repeated GPT Analysis of Note #1 for EKG subscore 10 times. Then, display mode of EKG subscore to ideally improve accuracy and precision of subscore.\n",
    "\n",
    "Please consider the patient's EKG findings. Would you categorize it as: [Normal (0)] [Non-specific repolarization disturbance (1)] [Significant ST deviation (2)] [Not enough information to determine EKG score (9)] Additional information: 1 point: No ST deviation but LBBB, LVH, repolarization changes (e.g. digoxin); 2 points: ST deviation not due to LBBB, LVH, or digoxin. Please provide your choice between the answers above in brackets  (e.g. [Normal (0)] ). No Prose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc0425",
   "metadata": {},
   "outputs": [],
   "source": [
    "ekgList = []\n",
    "prompt = \"Please consider the patient's EKG findings. Would you categorize it as: [Normal (0)] [Non-specific repolarization disturbance (1)] [Significant ST deviation (2)] [Not enough information to determine EKG score (9)] Additional information: 1 point: No ST deviation but LBBB, LVH, repolarization changes (e.g. digoxin); 2 points: ST deviation not due to LBBB, LVH, or digoxin. Please provide your choice between the answers above in brackets  (e.g. [Normal (0)] ). No Prose\"\n",
    "for x in range(0, 9):\n",
    "    messages = [{\"role\": \"user\", \"content\": (prompt + file_contents)}]\n",
    "    response = openai.ChatCompletion.create(engine=deployment_name, messages=messages)\n",
    "    for i, choice in enumerate(response[\"choices\"], start=1):\n",
    "        phrase = choice[\"message\"][\"content\"]\n",
    "        for ch in phrase:\n",
    "            if ch.isnumeric():\n",
    "                ekgList.append(ch)\n",
    "        print(choice[\"message\"][\"content\"])\n",
    "modeEKG = max(set(ekgList), key=ekgList.count)\n",
    "print(\"Mode EKG:\", modeEKG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd76982e",
   "metadata": {},
   "source": [
    "### Mode Analysis for Age Subscore\n",
    "#### Repeated GPT Analysis of Note #1 for Age subscore 10 times. Then, display mode of Age subscore to ideally improve accuracy and precision of subscore.\n",
    "\n",
    "Based on the encounter note log below, how would you classify the patient's age: \n",
    "[<45 (0)] [45-64 (1)] [>= 65 (2)]  [Not enough information to determine Age score]\n",
    "\n",
    "Please provide your choice between the answers above in brackets (e.g. [<45 (0)] ). No Prose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c92e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ageList = []\n",
    "def isolateString(ch1,ch2,s):\n",
    "    return s[s.find(ch1)+1:s.find(ch2)]\n",
    "prompt = \"Based on the encounter note log below, how would you classify the patient's age: [<45 (0)] [45-64 (1)] [>= 65 (2)]  [Not enough information to determine Age score] Please provide your choice between the answers above in brackets (e.g. [<45 (0)] ). No Prose.\"\n",
    "for x in range(0, 9):\n",
    "    messages = [{\"role\": \"user\", \"content\": (prompt + file_contents)}]\n",
    "    response = openai.ChatCompletion.create(engine=deployment_name, messages=messages)\n",
    "    for i, choice in enumerate(response[\"choices\"], start=1):\n",
    "        phrase = choice[\"message\"][\"content\"]\n",
    "        ageList.append(isolateString(\"(\", \")\", phrase))\n",
    "        print(choice[\"message\"][\"content\"])\n",
    "modeAge = max(set(ageList), key=ageList.count)\n",
    "print(\"Mode Age:\", modeAge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2aafed",
   "metadata": {},
   "source": [
    "### Mode Analysis for Risk Factors Subscore\n",
    "#### Repeated GPT Analysis of Note #1 for Risk Factors subscore 10 times. Then, display mode of Risk Factors subscore to ideally improve accuracy and precision of subscore.\n",
    "\n",
    "Consider the following risk factors: HTN, hypercholesterolemia, DM, obesity (BMI >30 kg/m²), smoking (current, or smoking cessation ≤3 mo), positive family history (parent or sibling with CVD before age 65); atherosclerotic disease: prior MI, PCI/CABG, CVA/TIA, or peripheral arterial disease. \n",
    "\n",
    "For the patient below, across all the combined encounter notes, how many risk factors are present? \n",
    "[No known risk factors (0)] [1-2 risk factors (1)] [>= 3 risk factors or history of atherosclerotic disease (2)] [Not enough information to determine Risk Factor score (9)]\n",
    "\n",
    "Please provide your final choice, listing one option between the answers above in brackets (e.g. [No known risk factors (0)] ). No Prose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb23be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "riskList = []\n",
    "prompt = \"Consider the following risk factors: HTN, hypercholesterolemia, DM, obesity (BMI >30 kg/m²), smoking (current, or smoking cessation ≤3 mo), positive family history (parent or sibling with CVD before age 65); atherosclerotic disease: prior MI, PCI/CABG, CVA/TIA, or peripheral arterial disease. For the patient below, across all the combined encounter notes, how many risk factors are present? [No known risk factors (0)] [1-2 risk factors (1)] [>= 3 risk factors or history of atherosclerotic disease (2)] [Not enough information to determine Risk Factor score (9)] Please provide your final choice, listing one option between the answers above in brackets (e.g. [No known risk factors (0)] ). No Prose.\"\n",
    "for x in range(0, 9):\n",
    "    messages = [{\"role\": \"user\", \"content\": (prompt + file_contents)}]\n",
    "    response = openai.ChatCompletion.create(engine=deployment_name, messages=messages)\n",
    "    for i, choice in enumerate(response[\"choices\"], start=1):\n",
    "        phrase = choice[\"message\"][\"content\"]\n",
    "        for ch in phrase:\n",
    "            if ch.isnumeric():\n",
    "                riskList.append(ch)\n",
    "        print(choice[\"message\"][\"content\"])\n",
    "modeRisk = max(set(riskList), key=riskList.count)\n",
    "print(\"Mode Risk:\", modeRisk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c96b20",
   "metadata": {},
   "source": [
    "### Mode Analysis for Troponins Subscore\n",
    "#### Repeated GPT Analysis of Note #1 for Troponins subscore 10 times. Then, display mode of Troponins subscore to ideally improve accuracy and precision of subscore.\n",
    "\n",
    "Find the troponin value in based on careful review of all of the encounter note logs provided below. Note that the troponins may be listed without a unit beside it. \n",
    "\n",
    "How would you categorize assessment of the patient's initial troponin measurement:[=< normal limit (0)] [1–3x normal limit (1)] [>3x normal limit (2)] [Not enough information to determine Troponin score (9)] \n",
    "\n",
    "The normal limit for high sensitivity troponin according to Yale New Haven Health is < 12 ng/L. \n",
    "\n",
    "Please provide your choice between the answers above in brackets (e.g. [=< normal limit (0)] ). No Prose.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a32d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tropList = []\n",
    "prompt = \"Find the troponin value based on careful review of all of the encounter note logs provided below. Note that the troponins may be listed without a unit beside it. How would you categorize assessment of the patient's initial troponin measurement:[=< normal limit (0)] [1–3x normal limit (1)] [>3x normal limit (2)] [Not enough information to determine Troponin score (9)] The normal limit for high sensitivity troponin according to Yale New Haven Health is < 12 ng/L. Please provide your choice between the answers above in brackets (e.g. [=< normal limit (0)] ). No Prose. \"\n",
    "for x in range(0, 9):\n",
    "    messages = [{\"role\": \"user\", \"content\": (prompt + file_contents)}]\n",
    "    response = openai.ChatCompletion.create(engine=deployment_name, messages=messages)\n",
    "    for i, choice in enumerate(response[\"choices\"], start=1):\n",
    "        phrase = choice[\"message\"][\"content\"]\n",
    "        tropList.append(isolateString(\"(\", \")\", phrase))\n",
    "        print(choice[\"message\"][\"content\"])\n",
    "modeTrop = max(set(tropList), key=tropList.count)\n",
    "print(\"Mode Troponin:\", modeTrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7138d619",
   "metadata": {},
   "source": [
    "### Final HEART Score\n",
    "The final HEART Score after summing each of the individual mode analysis of the subscore prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalHeart = int(modeHistory) + int(modeEKG) + int(modeAge) + int(modeRisk) + int(modeTrop)\n",
    "print(\"Total Heart Score:\", totalHeart)\n",
    "# should be # 2 + 1 + 2 + 2 + 2 = 9?\n",
    "# hmm I got 2 + 2 + 2 + 3 + 2 = 11? \n",
    "# EKG and Risk Factors are different. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
